# OVCamo

Related Paper: Open-Vocabulary Camouflaged Object Segmentation

## Dataset Details

### Prepare Related Data

- Collected by Fan *et al.*: <https://github.com/GewelsJI/SINet-V2>
  - **COD10K**, **CHAMELEON**: <https://drive.google.com/file/d/1M8-Ivd33KslvyehLK9_IUBGJ_Kf52bWG/view?usp=sharing>
- **PlantCamo**: <https://github.com/yjybuaa/PlantCamo>
- **CPD1K**: <https://github.com/xfflyer/Camouflaged-people-detection>
- Annotated and Generated by Cheng *et al.*: <https://github.com/XuelianCheng/SLT-Net>
  - **MoCA-Mask**: <https://drive.google.com/file/d/1FB24BGVrPOeUpmYbKZJYL5ermqUvBo_6/view?usp=sharing>
  - **CAD**: <http://vis-www.cs.umass.edu/motionSegmentation/>
    - Mask Generated by SLT-Net: <https://drive.google.com/file/d/1LwswF3axQ0BSC6DllTpyL77Ktruy-6M6/view?usp=sharing>

### Data Usage

1. Unzip all the files and set the following path information in the project's `.env`:
     - `COD10K_TRAIN_DIR`: Directory of the train set of **COD10K**, which contains `Imgs` and `GT` in `COD-TrainDataset`.
     - `COD10K_TEST_DIR`: Directory of the test set of **COD10K**, which is the path of `COD10K` in `COD-TestDataset`.
     - `CHAMELEON_DIR`: Directory of **CHAMELEON**, which is the path of `CHAMELEON` in `TestDataset_per_sq`.
     - `PlantCamo_DIR`: Directory of **PlantCamo**, which contains `train` and `test` directories of **PlantCamo**.
     - `CPD1K_DIR`: Directory of **CPD1K**, which contains `img` and `gt` of CPD1K.
     - `MoCA-Mask_DIR`: Directory of **MoCA-Mask**, which contains `TrainDataset_per_sq` and `TestDataset_per_sq`.
     - `CAD_IMAGE_DIR`: Directory of **CAD** images, which contains directories of all sequences.
     - `CAD_MASK_DIR`: Directory of **CAD** masks generated by SLT-Net, which contains directories of all sequences.
2. Specify the data roots for training and testing, and run the script to split the dataset: `python split_dataset.py --data-json ovcamo.json --train_root TRAIN_ROOT --test_root TEST_ROOT`
3. Use the training and testing splits of dataset in the training and inference process.

## LICENSE of OVCamo

<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://github.com/lartpang/OVCamo">OVCamo</a> by <span property="cc:attributionName">Youwei Pang, Xiaoqi Zhao, Jiaming Zuo, Lihe Zhang, Huchuan Lu</span> is licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1" alt=""><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1" alt=""></a></p>
